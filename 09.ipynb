{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率ロボティクス2017第9回\n",
    "\n",
    "上田隆一\n",
    "\n",
    "2017年11月15日@千葉工業大学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今日やること\n",
    "\n",
    "* 強化学習（古典的なもの）\n",
    "* 参考: [Sutton and Barto, 三上, 皆川訳: 強化学習, 森北出版, 2000.](https://www.amazon.co.jp/dp/4627826613)\n",
    "  * [ウェブ版 ](http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html)\n",
    "  * [そろそろ第2版が出るらしい](http://www.freetechbooks.com/reinforcement-learning-an-introduction-second-edition-draft-t1282.html)\n",
    "  \n",
    "## 強化学習（reinforcement learning）\n",
    "\n",
    "* 機械学習の一種\n",
    "  * 起源: 動物の心理学研究から[宮崎2005]\n",
    "    * 餌にありつけるような/危険を避けるような行動の学習\n",
    "  * 最近ANN（人工ニューラルネットワーク）との組み合わせで脚光を浴びている\n",
    "  \n",
    "## 基本的な強化学習の問題\n",
    "\n",
    "* 有限MDPでの行動決定の問題に一つ制限を与える\n",
    "  * 状態遷移と報酬が、行動しないと分からない。\n",
    "* 問題の定義\n",
    "  * 時刻: $\\mathcal{T} = \\{t | t = 0,1,2,\\dots,T \\}$\n",
    "  * 状態: $\\mathcal{S} = \\{s_i | i = 1,2,3,\\dots,N\\}$\n",
    "    * うち、いくつかは終端状態の集合$\\mathcal{S}_\\text{f}$に含まれる\n",
    "  * 行動: $\\mathcal{A} = \\{a_j | j = 1,2,3,\\dots,M\\}$\n",
    "  * 状態遷移や報酬は時不変だが自明でない\n",
    "    * ある確率分布に従って状態遷移する\n",
    "    * ある法則に従って報酬が与えられる \n",
    "\n",
    "## 何を求めたいのか\n",
    "\n",
    "* 「最適方策」を求める\n",
    "* 方策（二種類）\n",
    "  * 決定論的方策: $\\pi : \\mathcal{S} \\to \\mathcal{A}$\n",
    "    * 状態が決まると行動が決まるもの\n",
    "  * 確率的な方策: $\\pi : \\mathcal{S}\\times \\mathcal{A} \\to \\Re$\n",
    "    * 状態$s$において行動$a$を選択する確率\n",
    "* 最適方策は決定論的になる（理由は次のページに）\n",
    "  * $\\pi^* : \\mathcal{S} \\to \\mathcal{A}$\n",
    "  \n",
    "## 問題を解く道具\n",
    "\n",
    "* ベルマン方程式が成り立つ\n",
    "  * $V^*(s) = \\max_{a \\in \\mathcal{A} } \\sum_{s' \\in \\mathcal{S}}\\mathcal{P}_{ss'}^a [V^*(s') +\\mathcal{R}_{ss'}^a ]$\n",
    "    * $V^*$: 最適状態価値関数\n",
    "    * 左辺の「$\\max_{a \\in \\mathcal{A} }$」を満たすものが最適方策$\\pi^*$\n",
    "* エージェントの「経験」\n",
    "  * 状態遷移: ある状態$s$で行動$a$を選択したら状態$s'$に遷移して報酬を得た\n",
    "  * たくさん行動すれば統計的な性質が得られる\n",
    "  * たくさん行動しなければ統計的な性質が得られない\n",
    "  \n",
    "## 問題の難しさ\n",
    "\n",
    "* 価値関数に停留点が一つでもあると、エージェントがその場に留まってしまう\n",
    "* 膨大な試行が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
